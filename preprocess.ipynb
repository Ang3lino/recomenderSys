{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocess.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNZv4+XZamV1jka4AEVoPHI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ang3lino/recomenderSys/blob/master/preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CR3zNvcKIY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-neqn25wZ-Vp",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess\n",
        "En este notebook tomamos un conjunto de datos de valoraciones de de usuarios sobre peliculas, como es costumbre no todos los usuarios han valorado todas las peliculas. Los indices de las peliculas no son contiguos.\n",
        "\n",
        "La complejidad computacional con los filtros colaborativos es $O(m\\times n^2)$, por lo que el preprocesamiento de datos creara un subconjunto usando los usuarios y los articulos mas usados y se crearan objetos con el modulo pickle pues se interesa en saber los articulos que compro el usuario $i$, los usuarios que compraron el articulo $a$ y que valoracion le dio el usuario $u$ al articulo $a$, expresado como $r_{u,a}$ reduciendo el espacio usado por la matriz y reduciendo la complejidad a $O(\\Omega)$ donde $\\Omega$ es unicamente el conjunto de usuarios que ha valorado algo.\n",
        "\n",
        "El dataset puede ser descargado de: \n",
        "https://www.kaggle.com/grouplens/movielens-20m-dataset/download ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfRa1FPhOF5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "# Counter: Coleccion capaz de contar el numero de ocurrencias de un objeto sobre otra coleccion\n",
        "from collections import Counter, defaultdict\n",
        "from tqdm import tqdm  # modulo cuya finalidad es dar un feedback del progreso de algun procedimiento"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly8yPmufJBxM",
        "colab_type": "code",
        "outputId": "19d08fec-07ea-4f8e-e61a-65d10dd315be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install tqdm --upgrade"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tqdm in /usr/local/lib/python3.6/dist-packages (4.43.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV4PV3u8OF8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def import_dataset(fdir: str, fname: str, colab=True) -> pd.DataFrame:\n",
        "  # import the dataset from the cloud\n",
        "  if colab:\n",
        "    from google.colab import drive  \n",
        "    drive.mount('/content/drive')\n",
        "  fabspath = os.path.join(fdir, fname)\n",
        "  return pd.read_csv(fabspath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae65dH1YOF95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tqdm.pandas()  # con esto podremos mostrar el progreso del metodo pandas.apply como pandas.progress_apply\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL04NF1ydRpS",
        "colab_type": "code",
        "outputId": "530cab76-05ae-489d-e6d6-070badbec089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "\n",
        "fdir = \"drive/My Drive/petroleo/movielens-20m-dataset\"\n",
        "fname = 'rating.csv'\n",
        "df = import_dataset(fdir, fname)\n",
        "df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:53:47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:31:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:33:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:32:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:29:40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating            timestamp\n",
              "0       1        2     3.5  2005-04-02 23:53:47\n",
              "1       1       29     3.5  2005-04-02 23:31:16\n",
              "2       1       32     3.5  2005-04-02 23:33:39\n",
              "3       1       47     3.5  2005-04-02 23:32:07\n",
              "4       1       50     3.5  2005-04-02 23:29:40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azZsLPGdhIBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sequential_indexes(ints: iter):\n",
        "    '''Dado algun iterable de enteros se retorna un diccionario donde se les asigna id donde estos son secuenciales.\n",
        "    [2,2,2,2,3,3,5,7,11] -> [0, 1, 2, 3, 4]'''\n",
        "    uniq = set(ints)\n",
        "    mapper = {}\n",
        "    count = 0\n",
        "    for n in uniq:\n",
        "        if not n in mapper:\n",
        "            mapper[n] = count \n",
        "            count += 1\n",
        "    return mapper \n",
        "\n",
        "def check_dataframe_indexes(df):\n",
        "    '''Funcion de ayuda para determinar si la funcion sequential_indexes funciona adecuadamente. '''\n",
        "    print(min(df.userId), max(df.userId), len(set(df.userId)))\n",
        "    print(min(df.movieId), max(df.movieId), len(set(df.movieId)))  # movieId is not sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gag5gdRrnHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_indexes(df, col_name) -> None:\n",
        "    '''Usando la funcion sequential_indexes actualizamos los indices del dataframe. Siento que no es necesario este paso.'''\n",
        "    mapper = sequential_indexes(df.loc[:, col_name])\n",
        "    print(f'Updating indexes for column {col_name}.')\n",
        "    # rows_count = df.shape[0]\n",
        "    # for i in tqdm(range(rows_count)):  # forma alternativa, mas lenta\n",
        "    #     df.at[i, col_name] = mapper[df.at[i, col_name]]\n",
        "    df.loc[:, col_name] = df.progress_apply(lambda row: mapper[row[col_name]], axis=1)  # para cada iteracion se trata a la fila, especificando axis=1\n",
        "    print(f'Indexes for {col_name} have been updated succesfully.')\n",
        "\n",
        "def shrink_df(df: pd.DataFrame, user_name: str, article_name: str, user_count: int, article_count: int) -> pd.DataFrame:\n",
        "    '''Funcion que retorna un subconjunto donde cada tupla es tal que tanto el usuario como el articulo es el mas comun.'''\n",
        "    user_id_counts = Counter(df[user_name])\n",
        "    article_id_counts = Counter(df[article_name])\n",
        "    common_users = [x for x, count in user_id_counts.most_common(user_count)]\n",
        "    common_articles = [x for x, count in article_id_counts.most_common(article_count)]\n",
        "    intersection = df[user_name].isin(common_users) & df[article_name].isin(common_articles)\n",
        "    small_df = df[intersection].copy()\n",
        "    return small_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3e-mrzc0CeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN0nXl577dok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_small_df(df: pd.DataFrame, user_name: str, article_name: str, user_count:int, article_count:int) -> pd.DataFrame:\n",
        "    small_df_name = f'small_ratings_{user_count}_{article_count}.csv'\n",
        "    fabspath = os.path.join(fdir, small_df_name)\n",
        "    if os.path.exists(fabspath):\n",
        "        small_df = pd.read_csv(fabspath)\n",
        "    else:\n",
        "        # particularmente en este dataset, solo se resta una unidad para hacer los indices de 0...n-1\n",
        "        df[user_name] = df[user_name] - 1  \n",
        "        update_indexes(df, article_name)\n",
        "\n",
        "        # let's remove timestamp since we don't take into consideration for the algorithm\n",
        "        df = df.drop(columns=['timestamp'])  \n",
        "        small_df = shrink_df(df, user_name, article_name, user_count, article_count)\n",
        "\n",
        "        # despues de actualizar el dataframe se habra que corregir los indices\n",
        "        update_indexes(small_df, user_name)\n",
        "        update_indexes(small_df, article_name)\n",
        "        small_df.to_csv(os.path.join(fdir, small_df_name))\n",
        "    return small_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUiQNgsM0WAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "user_name, article_name = 'userId', 'movieId'\n",
        "user_count, article_count = 4096, 512\n",
        "small_df = get_small_df(df, user_name, article_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC3UyNMDOoYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_dict(fname: str, default_dictionary: defaultdict) -> None:\n",
        "    # fdir, user_count, article_count\n",
        "    fname = f'{fname}_{user_count}_{article_count}.json'\n",
        "    with open(os.path.join(fdir, fname), 'wb') as f:\n",
        "        pickle.dump(default_dictionary, f)\n",
        "\n",
        "def build_mappers(df: pd.DataFrame, user_label: str, article_label: str, rating_label: str) -> None:\n",
        "    user2art, art2user = defaultdict(list), defaultdict(list)\n",
        "    user_art2rat = dict()\n",
        "    for i, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
        "        u, a = row[user_label], row[article_label]\n",
        "        user2art[u].append(a)\n",
        "        art2user[a].append(u)\n",
        "        user_art2rat[(u, a)] = row[rating_label] \n",
        "    save_dict('user2article', user2art)\n",
        "    save_dict('article2user', art2user)\n",
        "    save_dict('user_article2rating', user_art2rat)\n",
        "    print('Elementos salvados satisfactoriamente.')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezt6Wn3eQjko",
        "colab_type": "code",
        "outputId": "3b361a30-d9bf-44ca-c8cf-c4da9f874cb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "build_mappers(small_df, 'userId', 'movieId', 'rating')\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1266269/1266269 [02:22<00:00, 8896.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Elementos salvados satisfactoriamente.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spt7ZGkhQmHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}